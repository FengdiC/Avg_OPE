{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "sys.path.insert(0, \"../disc_cop\")\n",
    "from disc_cop.envs import ENV_ID_TO_NAME\n",
    "\n",
    "import _pickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = \"/Volumes/Expansion/icml_2025/avg_ope/cc_results/results/saved_models\"\n",
    "stats_file = \"/Volumes/Expansion/icml_2025/avg_ope/cc_results/results/processed_best.feather\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "\n",
    "for env_name in ENV_ID_TO_NAME.values():\n",
    "    if not os.path.isdir(os.path.join(result_dir, env_name)):\n",
    "        print(\"{} not processed\".format(env_name))\n",
    "        continue\n",
    "\n",
    "    for run_file in tqdm(os.listdir(os.path.join(result_dir, env_name)), desc=env_name):\n",
    "        if run_file.startswith(\".\"):\n",
    "            continue\n",
    "\n",
    "        prefix = run_file.split(\"-\")[:4]\n",
    "\n",
    "        for seed in range(10):\n",
    "            torch_path = os.path.join(result_dir, env_name, run_file, \"seed_{}-curr_best.pt\".format(seed))\n",
    "            data = torch.load(torch_path)\n",
    "            curr_loss = data[\"loss\"]\n",
    "            curr_steps = data[\"steps\"]\n",
    "\n",
    "            stats.append(\n",
    "                dict(\n",
    "                    variant=run_file,\n",
    "                    env_name=env_name,\n",
    "                    seed=seed,\n",
    "                    **{\n",
    "                        \"_\".join(key_val.split(\"_\")[:-1]): key_val.split(\"_\")[-1] for key_val in prefix\n",
    "                    },\n",
    "                    loss=curr_loss,\n",
    "                    steps=curr_steps,\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame(stats)\n",
    "stats.to_feather(stats_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
